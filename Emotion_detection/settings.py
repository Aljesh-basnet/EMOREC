"""
Django settings for Emotion_detection project.

Generated by 'django-admin startproject' using Django 3.1.2.

For more information on this file, see
https://docs.djangoproject.com/en/3.1/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/3.1/ref/settings/
"""

from pathlib import Path,os


# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/3.1/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = 'v_!^_n4zz(0_^neh@=**i-qhwvh-le_&zp(-!%*da74-5%@*c1'

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = False

ALLOWED_HOSTS = ['emorec1.herokuapp.com','127.0.0.1']


# Application definition

INSTALLED_APPS = [
    'users.apps.UsersConfig',
    'AI.apps.AiConfig',
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
   

]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'Emotion_detection.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [os.path.join(BASE_DIR,'templates'),os.path.join(BASE_DIR,'AI_files')],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'Emotion_detection.wsgi.application'


# Database
# https://docs.djangoproject.com/en/3.1/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': BASE_DIR / 'db.sqlite',
    }
}


# Password validation
# https://docs.djangoproject.com/en/3.1/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/3.1/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_L10N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/3.1/howto/static-files/

STATIC_URL = '/static/'
STATICFILES_DIRS = [
    os.path.join(BASE_DIR, 'static')
]
STATIC_ROOT =os.path.join(BASE_DIR,'assets')

EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
EMAIL_HOST ='smtp.gmail.com'
EMAIL_PORT= 587
EMAIL_HOST_USER= 'basnetaljesh05@gmail.com'
EMAIL_HOST_PASSWORD = 'yirzxuxqsrvrtumu'
EMAIL_USE_TLS = True

import numpy as np
import tensorflow.keras as keras
import pandas as pd
from tensorflow.keras.models import load_model
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer
from tensorflow.keras.preprocessing.text import Tokenizer
import re
df_train = pd.read_csv('AI_files/train.txt', header =None, sep =';', names = ['Texts','Emotions'], encoding='utf-8')
df_test = pd.read_csv('AI_files/test.txt', header = None, sep =';', names = ['Texts','Emotions'],encoding='utf-8')
df_val = pd.read_csv('AI_files/val.txt', header = None, sep =';', names = ['Texts','Emotions'],encoding='utf-8')
modelreload = load_model('AI_files/Bilstm_model.h5')


import re 
text = ' '.join(df_train.iloc[:,0])
text =text.split()
common = pd.Series(text).value_counts()
rare =common[common.values == 1]

def clean(x):
    if type(x) is str:
        x=x.lower()
        x = re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9_-]+)', '', x) 
        #regex to remove to emails
        x = re.sub(r'(http|ftp|https)://([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?', '', x)
        #regex to remove URLs
        x = re.sub('[^A-Z a-z]+', '', x)
        x = ' '.join([t for t in x.split() if t not in rare])
        return x
    else:
        return x
    

stopwords = stopwords.words('english')
def remove_stop_words(corpus):
    removed_stop_words = []
    for review in corpus:
        removed_stop_words.append(
            ' '.join([word for word in review.split() 
                      if word not in stopwords])
        )
    return removed_stop_words

def get_stemmed_text(x):
    stemmer = PorterStemmer()
    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in x]

def get_lemmatized_text(x):
    lemmatizer = WordNetLemmatizer()
    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in x]

emotions={0:'joy',1:'anger',2:'love',3:'sadness',4:'fear',5:'surprise'}
token =Tokenizer(lower=True,filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',oov_token='UNK')
max_length =25

def preprocessing():
    
    df_train.iloc[:,0] = df_train.iloc[:,0].apply(lambda x: clean(x)) 
    df_test.iloc[:,0] = df_test.iloc[:,0].apply(lambda x: clean(x))
    df_val.iloc[:,0] = df_val.iloc[:,0].apply(lambda x: clean(x))

    x_train =df_train.iloc[:,0].tolist()
    x_val=df_val.iloc[:,0].tolist()
    x_test = df_test.iloc[:,0].tolist()

    
    x_train = np.array(x_train)
    x_test = np.array(x_test)
    x_val = np.array(x_val)

    x_train = remove_stop_words(x_train)
    x_test = remove_stop_words(x_test)
    x_val= remove_stop_words(x_val)

    x_train = get_stemmed_text(x_train)
    x_test = get_stemmed_text(x_test)
    x_val = get_stemmed_text(x_val)

    x_train = get_lemmatized_text(x_train)
    x_test = get_lemmatized_text(x_test)
    x_val = get_lemmatized_text(x_val)
    total_text = np.concatenate((x_train,x_test,x_val),axis=0)
    return total_text